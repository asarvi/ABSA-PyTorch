{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo0nrH2o5XqO",
        "colab_type": "code",
        "outputId": "18766cc4-e98f-4d2e-9f93-32bebc3e64d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "! git clone https://github.com/asarvi/ABSA-PyTorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ABSA-PyTorch'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 358 (delta 2), reused 0 (delta 0), pack-reused 352\u001b[K\n",
            "Receiving objects: 100% (358/358), 1.57 MiB | 9.78 MiB/s, done.\n",
            "Resolving deltas: 100% (224/224), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dimGz_pWyvke",
        "colab_type": "code",
        "outputId": "79044a49-2c50-4393-93c9-9951ef8f62ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "! git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)   \u001b[K\rremote: Counting objects:  40% (2/5)   \u001b[K\rremote: Counting objects:  60% (3/5)   \u001b[K\rremote: Counting objects:  80% (4/5)   \u001b[K\rremote: Counting objects: 100% (5/5)   \u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)   \u001b[K\rremote: Compressing objects:  66% (2/3)   \u001b[K\rremote: Compressing objects: 100% (3/3)   \u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/asarvi/ABSA-PyTorch\n",
            "   03f32c2..4c76694  master     -> origin/master\n",
            "Updating 03f32c2..4c76694\n",
            "Fast-forward\n",
            " infer_example.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4riyel1y0XK",
        "colab_type": "code",
        "outputId": "b9d387f6-c822-4216-ac2e-339799c80f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%cd ABSA-PyTorch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'ABSA-PyTorch'\n",
            "/content/ABSA-PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUt7or12003M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJpCcp2n05kQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8u_A7SRzA62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q torch==1.1.0 torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_o_npK0akT",
        "colab_type": "code",
        "outputId": "6b3cb933-158d-4dc0-e67d-778a3ffb06ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LFrNLZk0meb",
        "colab_type": "code",
        "outputId": "654835ce-c07f-4323-ab41-a097e9e16d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "! pip install pytorch-pretrained-BERT"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-BERT\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-pretrained-BERT)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-BERT) (1.9.199)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-BERT) (1.16.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-BERT) (4.28.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-BERT) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-BERT) (2.21.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-BERT) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-BERT) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.199 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-BERT) (1.12.199)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-BERT) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-BERT) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-BERT) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-BERT) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-pretrained-BERT) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.199->boto3->pytorch-pretrained-BERT) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.199->boto3->pytorch-pretrained-BERT) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604152 sha256=4186c5dde6544267a78cfaf1d4571ba03ef5e92210794f8b146321d5fbac445f\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-BERT\n",
            "Successfully installed pytorch-pretrained-BERT-0.6.2 regex-2019.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbn5U1kO07Vy",
        "colab_type": "code",
        "outputId": "baee9d56-f3d2-44c5-bcc6-70be785d2592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "! wget http://nlp.stanford.edu/data/glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-04 12:41:41--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2019-08-04 12:41:41--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2019-08-04 12:41:41--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  42.5MB/s    in 41s     \n",
            "\n",
            "2019-08-04 12:42:23 (43.2 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DZSJuXk1FtK",
        "colab_type": "code",
        "outputId": "4a61d54e-d2f6-4c59-cf88-0198810455f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "! wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-04 12:43:41--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-08-04 12:43:41--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2019-08-04 12:43:41--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  41.7MB/s    in 34s     \n",
            "\n",
            "2019-08-04 12:44:15 (42.8 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha9A9c4e1TQS",
        "colab_type": "code",
        "outputId": "3fe5f742-b26a-499a-daea-2dbe591c669f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "! unzip -e glove.42B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6y_wc2Y1W7Q",
        "colab_type": "code",
        "outputId": "37d5a803-4865-41e9-b7fa-1477f59bc945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "! unzip -e! wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP.\n",
            "\n",
            "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\n",
            "  Default action is to extract files in list, except those in xlist, to exdir;\n",
            "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\n",
            "\n",
            "  -p  extract files to pipe, no messages     -l  list files (short format)\n",
            "  -f  freshen existing files, create none    -t  test compressed archive data\n",
            "  -u  update files, create if necessary      -z  display archive comment only\n",
            "  -v  list verbosely/show version info       -T  timestamp archive to latest\n",
            "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\n",
            "modifiers:\n",
            "  -n  never overwrite existing files         -q  quiet mode (-qq => quieter)\n",
            "  -o  overwrite files WITHOUT prompting      -a  auto-convert any text files\n",
            "  -j  junk paths (do not make directories)   -aa treat ALL files as text\n",
            "  -U  use escapes for all non-ASCII Unicode  -UU ignore any Unicode fields\n",
            "  -C  match filenames case-insensitively     -L  make (some) names lowercase\n",
            "  -X  restore UID/GID info                   -V  retain VMS version numbers\n",
            "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\n",
            "  -O CHARSET  specify a character encoding for DOS, Windows and OS/2 archives\n",
            "  -I CHARSET  specify a character encoding for UNIX and other archives\n",
            "\n",
            "See \"unzip -hh\" or unzip.txt for more help.  Examples:\n",
            "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\n",
            "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\n",
            "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDjidBm-2EfS",
        "colab_type": "code",
        "outputId": "1f848456-a425-4b6e-f6fd-08cf251edd64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --model_name memnet  --dataset restaurant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading tokenizer: restaurant_tokenizer.dat\n",
            "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n",
            "cuda memory allocated: 6957568\n",
            "n_trainable_params: 362703, n_nontrainable_params: 1375500\n",
            "> training arguments:\n",
            ">>> model_name: memnet\n",
            ">>> dataset: restaurant\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fbccbb9f158>\n",
            ">>> learning_rate: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 10\n",
            ">>> batch_size: 64\n",
            ">>> log_step: 5\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 80\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> device: cuda\n",
            ">>> seed: None\n",
            ">>> valset_ratio: 0\n",
            ">>> model_class: <class 'models.memnet.MemNet'>\n",
            ">>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}\n",
            ">>> inputs_cols: ['text_raw_without_aspect_indices', 'aspect_indices']\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "/content/ABSA-PyTorch/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "loss: 1.4493, acc: 0.2687\n",
            "loss: 1.3534, acc: 0.3078\n",
            "loss: 1.2932, acc: 0.3302\n",
            "loss: 1.2372, acc: 0.3633\n",
            "loss: 1.1885, acc: 0.3919\n",
            "loss: 1.1655, acc: 0.4167\n",
            "loss: 1.1414, acc: 0.4388\n",
            "loss: 1.1275, acc: 0.4520\n",
            "loss: 1.1179, acc: 0.4583\n",
            "loss: 1.1085, acc: 0.4644\n",
            "loss: 1.0978, acc: 0.4730\n",
            "> val_acc: 0.5777, val_f1: 0.3234\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.5777\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 1\n",
            "loss: 0.9828, acc: 0.5781\n",
            "loss: 1.0194, acc: 0.5430\n",
            "loss: 1.0165, acc: 0.5445\n",
            "loss: 1.0018, acc: 0.5486\n",
            "loss: 0.9960, acc: 0.5496\n",
            "loss: 0.9880, acc: 0.5525\n",
            "loss: 0.9812, acc: 0.5601\n",
            "loss: 0.9816, acc: 0.5563\n",
            "loss: 0.9712, acc: 0.5632\n",
            "loss: 0.9659, acc: 0.5658\n",
            "loss: 0.9607, acc: 0.5708\n",
            "> val_acc: 0.6321, val_f1: 0.3194\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6321\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 2\n",
            "loss: 0.9022, acc: 0.5938\n",
            "loss: 0.9436, acc: 0.5859\n",
            "loss: 0.9689, acc: 0.5597\n",
            "loss: 0.9389, acc: 0.5830\n",
            "loss: 0.9324, acc: 0.5900\n",
            "loss: 0.9334, acc: 0.5877\n",
            "loss: 0.9303, acc: 0.5867\n",
            "loss: 0.9202, acc: 0.5903\n",
            "loss: 0.9219, acc: 0.5903\n",
            "loss: 0.9203, acc: 0.5914\n",
            "loss: 0.9211, acc: 0.5898\n",
            "loss: 0.9221, acc: 0.5912\n",
            "> val_acc: 0.6402, val_f1: 0.3528\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6402\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 3\n",
            "loss: 0.9249, acc: 0.5664\n",
            "loss: 0.9064, acc: 0.5903\n",
            "loss: 0.8955, acc: 0.6049\n",
            "loss: 0.9121, acc: 0.5954\n",
            "loss: 0.8995, acc: 0.6009\n",
            "loss: 0.9028, acc: 0.5964\n",
            "loss: 0.9004, acc: 0.5983\n",
            "loss: 0.9018, acc: 0.5982\n",
            "loss: 0.8986, acc: 0.5998\n",
            "loss: 0.9004, acc: 0.5966\n",
            "loss: 0.9005, acc: 0.5981\n",
            "> val_acc: 0.6536, val_f1: 0.3810\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6536\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 4\n",
            "loss: 0.8888, acc: 0.5938\n",
            "loss: 0.8823, acc: 0.6205\n",
            "loss: 0.8798, acc: 0.6211\n",
            "loss: 0.8693, acc: 0.6278\n",
            "loss: 0.8823, acc: 0.6172\n",
            "loss: 0.8883, acc: 0.6094\n",
            "loss: 0.8823, acc: 0.6167\n",
            "loss: 0.8811, acc: 0.6170\n",
            "loss: 0.8854, acc: 0.6131\n",
            "loss: 0.8770, acc: 0.6174\n",
            "loss: 0.8763, acc: 0.6163\n",
            "loss: 0.8777, acc: 0.6117\n",
            "> val_acc: 0.6723, val_f1: 0.4261\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6723\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 5\n",
            "loss: 0.8413, acc: 0.6500\n",
            "loss: 0.8449, acc: 0.6391\n",
            "loss: 0.8587, acc: 0.6281\n",
            "loss: 0.8734, acc: 0.6109\n",
            "loss: 0.8672, acc: 0.6156\n",
            "loss: 0.8644, acc: 0.6167\n",
            "loss: 0.8644, acc: 0.6179\n",
            "loss: 0.8624, acc: 0.6191\n",
            "loss: 0.8579, acc: 0.6205\n",
            "loss: 0.8525, acc: 0.6259\n",
            "loss: 0.8572, acc: 0.6233\n",
            "> val_acc: 0.6795, val_f1: 0.4033\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6795\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 6\n",
            "loss: 0.8608, acc: 0.6146\n",
            "loss: 0.8583, acc: 0.6172\n",
            "loss: 0.8608, acc: 0.6130\n",
            "loss: 0.8712, acc: 0.6094\n",
            "loss: 0.8579, acc: 0.6257\n",
            "loss: 0.8566, acc: 0.6317\n",
            "loss: 0.8500, acc: 0.6326\n",
            "loss: 0.8433, acc: 0.6345\n",
            "loss: 0.8413, acc: 0.6337\n",
            "loss: 0.8437, acc: 0.6299\n",
            "loss: 0.8426, acc: 0.6306\n",
            "> val_acc: 0.6804, val_f1: 0.4557\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6804\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 7\n",
            "loss: 0.8859, acc: 0.6250\n",
            "loss: 0.8475, acc: 0.6484\n",
            "loss: 0.8394, acc: 0.6577\n",
            "loss: 0.8261, acc: 0.6641\n",
            "loss: 0.8219, acc: 0.6615\n",
            "loss: 0.8169, acc: 0.6581\n",
            "loss: 0.8194, acc: 0.6547\n",
            "loss: 0.8255, acc: 0.6506\n",
            "loss: 0.8271, acc: 0.6467\n",
            "loss: 0.8300, acc: 0.6430\n",
            "loss: 0.8276, acc: 0.6443\n",
            "loss: 0.8285, acc: 0.6440\n",
            "> val_acc: 0.6893, val_f1: 0.4496\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6893\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 8\n",
            "loss: 0.8749, acc: 0.6250\n",
            "loss: 0.8528, acc: 0.6285\n",
            "loss: 0.8428, acc: 0.6239\n",
            "loss: 0.8325, acc: 0.6390\n",
            "loss: 0.8280, acc: 0.6458\n",
            "loss: 0.8196, acc: 0.6482\n",
            "loss: 0.8148, acc: 0.6526\n",
            "loss: 0.8072, acc: 0.6550\n",
            "loss: 0.8098, acc: 0.6538\n",
            "loss: 0.8133, acc: 0.6505\n",
            "loss: 0.8145, acc: 0.6479\n",
            "> val_acc: 0.6946, val_f1: 0.4839\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.6946\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 9\n",
            "loss: 0.8115, acc: 0.6484\n",
            "loss: 0.8224, acc: 0.6295\n",
            "loss: 0.8148, acc: 0.6380\n",
            "loss: 0.8059, acc: 0.6517\n",
            "loss: 0.8117, acc: 0.6456\n",
            "loss: 0.8021, acc: 0.6493\n",
            "loss: 0.8012, acc: 0.6509\n",
            "loss: 0.8019, acc: 0.6512\n",
            "loss: 0.8025, acc: 0.6518\n",
            "loss: 0.8015, acc: 0.6539\n",
            "loss: 0.8025, acc: 0.6517\n",
            "loss: 0.7963, acc: 0.6563\n",
            "> val_acc: 0.7045, val_f1: 0.4801\n",
            ">> saved: state_dict/memnet_restaurant_val_acc0.7045\n",
            ">> test_acc: 0.7045, test_f1: 0.4801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWx51VHKmY54",
        "colab_type": "code",
        "outputId": "c2eb0567-ce23-46b5-f4c4-4092f4a1b0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train_k_fold_cross_val.py --model_name bert_spc --dataset restaurant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpt9klsjve\n",
            "Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "cuda memory allocated: 439071232\n",
            "n_trainable_params: 109484547, n_nontrainable_params: 0\n",
            "> training arguments:\n",
            ">>> model_name: bert_spc\n",
            ">>> dataset: restaurant\n",
            ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
            ">>> initializer: <function xavier_uniform_ at 0x7fefecc3ae18>\n",
            ">>> learning_rate: 2e-05\n",
            ">>> dropout: 0.1\n",
            ">>> l2reg: 0.01\n",
            ">>> num_epoch: 10\n",
            ">>> batch_size: 64\n",
            ">>> log_step: 10\n",
            ">>> embed_dim: 300\n",
            ">>> hidden_dim: 300\n",
            ">>> bert_dim: 768\n",
            ">>> pretrained_bert_name: bert-base-uncased\n",
            ">>> max_seq_len: 80\n",
            ">>> polarities_dim: 3\n",
            ">>> hops: 3\n",
            ">>> device: cuda\n",
            ">>> seed: None\n",
            ">>> cross_val_fold: 10\n",
            ">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",
            ">>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}\n",
            ">>> inputs_cols: ['text_bert_indices', 'bert_segments_ids']\n",
            "fold : 0\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.0718, acc: 0.5219\n",
            "loss: 1.0375, acc: 0.5406\n",
            "loss: 0.9966, acc: 0.5687\n",
            "loss: 0.9871, acc: 0.5758\n",
            "loss: 0.9841, acc: 0.5759\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "> val_acc: 0.5889, val_f1: 0.2610\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.8853, acc: 0.6389\n",
            "loss: 0.8923, acc: 0.6266\n",
            "loss: 0.8777, acc: 0.6245\n",
            "loss: 0.8668, acc: 0.6210\n",
            "loss: 0.8472, acc: 0.6320\n",
            "> val_acc: 0.6528, val_f1: 0.4840\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 2\n",
            "loss: 0.6788, acc: 0.6973\n",
            "loss: 0.6774, acc: 0.7066\n",
            "loss: 0.6592, acc: 0.7143\n",
            "loss: 0.6267, acc: 0.7311\n",
            "loss: 0.6230, acc: 0.7350\n",
            "> val_acc: 0.7389, val_f1: 0.6449\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.5098, acc: 0.7924\n",
            "loss: 0.5138, acc: 0.7932\n",
            "loss: 0.5058, acc: 0.7969\n",
            "loss: 0.5075, acc: 0.7969\n",
            "loss: 0.5025, acc: 0.7952\n",
            "> val_acc: 0.7472, val_f1: 0.6655\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.3577, acc: 0.8698\n",
            "loss: 0.3802, acc: 0.8516\n",
            "loss: 0.4085, acc: 0.8431\n",
            "loss: 0.4254, acc: 0.8398\n",
            "loss: 0.4267, acc: 0.8390\n",
            "> val_acc: 0.7611, val_f1: 0.6785\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.3359, acc: 0.8719\n",
            "loss: 0.3217, acc: 0.8708\n",
            "loss: 0.3132, acc: 0.8756\n",
            "loss: 0.3090, acc: 0.8817\n",
            "loss: 0.3143, acc: 0.8823\n",
            "> val_acc: 0.7889, val_f1: 0.7119\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.2689, acc: 0.9062\n",
            "loss: 0.2709, acc: 0.9051\n",
            "loss: 0.2748, acc: 0.9004\n",
            "loss: 0.2712, acc: 0.9026\n",
            "loss: 0.2718, acc: 0.9013\n",
            "> val_acc: 0.7778, val_f1: 0.7102\n",
            "epoch: 7\n",
            "loss: 0.1917, acc: 0.9323\n",
            "loss: 0.1655, acc: 0.9471\n",
            "loss: 0.1774, acc: 0.9436\n",
            "loss: 0.1797, acc: 0.9380\n",
            "loss: 0.1767, acc: 0.9400\n",
            "> val_acc: 0.7722, val_f1: 0.7124\n",
            "epoch: 8\n",
            "loss: 0.1751, acc: 0.9453\n",
            "loss: 0.1530, acc: 0.9531\n",
            "loss: 0.1500, acc: 0.9503\n",
            "loss: 0.1574, acc: 0.9468\n",
            "loss: 0.1580, acc: 0.9457\n",
            "> val_acc: 0.7750, val_f1: 0.7146\n",
            "epoch: 9\n",
            "loss: 0.0850, acc: 0.9688\n",
            "loss: 0.0770, acc: 0.9801\n",
            "loss: 0.0908, acc: 0.9695\n",
            "loss: 0.1043, acc: 0.9627\n",
            "loss: 0.1143, acc: 0.9596\n",
            "loss: 0.1166, acc: 0.9578\n",
            "> val_acc: 0.7806, val_f1: 0.7214\n",
            ">> test_acc: 0.8187, test_f1: 0.7046\n",
            "fold : 1\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.2549, acc: 0.4938\n",
            "loss: 1.1163, acc: 0.5359\n",
            "loss: 1.0682, acc: 0.5500\n",
            "loss: 1.0224, acc: 0.5691\n",
            "loss: 1.0033, acc: 0.5763\n",
            "> val_acc: 0.5889, val_f1: 0.2471\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9076, acc: 0.6076\n",
            "loss: 0.8999, acc: 0.6209\n",
            "loss: 0.8993, acc: 0.6169\n",
            "loss: 0.8839, acc: 0.6226\n",
            "loss: 0.8736, acc: 0.6234\n",
            "> val_acc: 0.6389, val_f1: 0.4338\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 2\n",
            "loss: 0.7533, acc: 0.6758\n",
            "loss: 0.7467, acc: 0.6849\n",
            "loss: 0.7400, acc: 0.6908\n",
            "loss: 0.7263, acc: 0.6974\n",
            "loss: 0.7157, acc: 0.7012\n",
            "> val_acc: 0.7167, val_f1: 0.5938\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.5849, acc: 0.7567\n",
            "loss: 0.5763, acc: 0.7629\n",
            "loss: 0.5834, acc: 0.7627\n",
            "loss: 0.5792, acc: 0.7631\n",
            "loss: 0.5937, acc: 0.7557\n",
            "> val_acc: 0.7167, val_f1: 0.5807\n",
            "epoch: 4\n",
            "loss: 0.5496, acc: 0.7760\n",
            "loss: 0.5438, acc: 0.7773\n",
            "loss: 0.5396, acc: 0.7770\n",
            "loss: 0.5311, acc: 0.7791\n",
            "loss: 0.5271, acc: 0.7833\n",
            "> val_acc: 0.7139, val_f1: 0.5972\n",
            "epoch: 5\n",
            "loss: 0.4234, acc: 0.8313\n",
            "loss: 0.4477, acc: 0.8146\n",
            "loss: 0.4539, acc: 0.8156\n",
            "loss: 0.4544, acc: 0.8161\n",
            "loss: 0.4538, acc: 0.8184\n",
            "> val_acc: 0.7250, val_f1: 0.5868\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.4214, acc: 0.8203\n",
            "loss: 0.3773, acc: 0.8493\n",
            "loss: 0.3866, acc: 0.8424\n",
            "loss: 0.3904, acc: 0.8428\n",
            "loss: 0.3963, acc: 0.8413\n",
            "> val_acc: 0.7500, val_f1: 0.6617\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.2940, acc: 0.8958\n",
            "loss: 0.3435, acc: 0.8678\n",
            "loss: 0.3371, acc: 0.8716\n",
            "loss: 0.3281, acc: 0.8750\n",
            "loss: 0.3308, acc: 0.8714\n",
            "> val_acc: 0.7528, val_f1: 0.6512\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 8\n",
            "loss: 0.3514, acc: 0.8594\n",
            "loss: 0.2881, acc: 0.8867\n",
            "loss: 0.2755, acc: 0.8935\n",
            "loss: 0.2752, acc: 0.8916\n",
            "loss: 0.2797, acc: 0.8903\n",
            "> val_acc: 0.7667, val_f1: 0.6867\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.2045, acc: 0.9062\n",
            "loss: 0.1861, acc: 0.9332\n",
            "loss: 0.2094, acc: 0.9219\n",
            "loss: 0.2200, acc: 0.9153\n",
            "loss: 0.2212, acc: 0.9120\n",
            "loss: 0.2287, acc: 0.9116\n",
            "> val_acc: 0.7694, val_f1: 0.6727\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            ">> test_acc: 0.8000, test_f1: 0.6830\n",
            "fold : 2\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.1191, acc: 0.4859\n",
            "loss: 1.0608, acc: 0.5289\n",
            "loss: 1.0354, acc: 0.5354\n",
            "loss: 1.0151, acc: 0.5531\n",
            "loss: 1.0000, acc: 0.5625\n",
            "> val_acc: 0.6389, val_f1: 0.2713\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9322, acc: 0.6094\n",
            "loss: 0.9389, acc: 0.6028\n",
            "loss: 0.9401, acc: 0.5927\n",
            "loss: 0.9459, acc: 0.5881\n",
            "loss: 0.9366, acc: 0.5957\n",
            "> val_acc: 0.6389, val_f1: 0.2713\n",
            "epoch: 2\n",
            "loss: 0.9430, acc: 0.5703\n",
            "loss: 0.9437, acc: 0.5842\n",
            "loss: 0.9202, acc: 0.5898\n",
            "loss: 0.9076, acc: 0.5979\n",
            "loss: 0.8902, acc: 0.6051\n",
            "> val_acc: 0.6667, val_f1: 0.3729\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.8564, acc: 0.6451\n",
            "loss: 0.8710, acc: 0.6121\n",
            "loss: 0.8661, acc: 0.6175\n",
            "loss: 0.8351, acc: 0.6360\n",
            "loss: 0.8155, acc: 0.6433\n",
            "> val_acc: 0.6972, val_f1: 0.4912\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.6800, acc: 0.7370\n",
            "loss: 0.6667, acc: 0.7256\n",
            "loss: 0.6472, acc: 0.7332\n",
            "loss: 0.6326, acc: 0.7409\n",
            "loss: 0.6252, acc: 0.7469\n",
            "> val_acc: 0.7389, val_f1: 0.6045\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.5724, acc: 0.7719\n",
            "loss: 0.5829, acc: 0.7677\n",
            "loss: 0.5624, acc: 0.7688\n",
            "loss: 0.5466, acc: 0.7754\n",
            "loss: 0.5436, acc: 0.7781\n",
            "> val_acc: 0.7389, val_f1: 0.5793\n",
            "epoch: 6\n",
            "loss: 0.5073, acc: 0.7930\n",
            "loss: 0.4607, acc: 0.8147\n",
            "loss: 0.4660, acc: 0.8151\n",
            "loss: 0.4652, acc: 0.8176\n",
            "loss: 0.4537, acc: 0.8235\n",
            "> val_acc: 0.7472, val_f1: 0.6394\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.3914, acc: 0.8594\n",
            "loss: 0.3879, acc: 0.8486\n",
            "loss: 0.3899, acc: 0.8417\n",
            "loss: 0.3866, acc: 0.8499\n",
            "loss: 0.3918, acc: 0.8485\n",
            "> val_acc: 0.7639, val_f1: 0.6576\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 8\n",
            "loss: 0.3857, acc: 0.8594\n",
            "loss: 0.3445, acc: 0.8659\n",
            "loss: 0.3365, acc: 0.8707\n",
            "loss: 0.3223, acc: 0.8765\n",
            "loss: 0.3219, acc: 0.8757\n",
            "> val_acc: 0.7861, val_f1: 0.6828\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.2880, acc: 0.9219\n",
            "loss: 0.2309, acc: 0.9119\n",
            "loss: 0.2454, acc: 0.9092\n",
            "loss: 0.2495, acc: 0.9062\n",
            "loss: 0.2600, acc: 0.9005\n",
            "loss: 0.2599, acc: 0.9021\n",
            "> val_acc: 0.8111, val_f1: 0.7061\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            ">> test_acc: 0.8348, test_f1: 0.7469\n",
            "fold : 3\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.1285, acc: 0.4953\n",
            "loss: 1.0457, acc: 0.5547\n",
            "loss: 1.0228, acc: 0.5630\n",
            "loss: 1.0123, acc: 0.5684\n",
            "loss: 0.9991, acc: 0.5772\n",
            "> val_acc: 0.5806, val_f1: 0.2449\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9327, acc: 0.6059\n",
            "loss: 0.9236, acc: 0.6127\n",
            "loss: 0.9292, acc: 0.6083\n",
            "loss: 0.9447, acc: 0.5978\n",
            "loss: 0.9497, acc: 0.5985\n",
            "> val_acc: 0.5806, val_f1: 0.2449\n",
            "epoch: 2\n",
            "loss: 0.9277, acc: 0.6172\n",
            "loss: 0.9491, acc: 0.5998\n",
            "loss: 0.9458, acc: 0.5971\n",
            "loss: 0.9419, acc: 0.5987\n",
            "loss: 0.9372, acc: 0.6019\n",
            "> val_acc: 0.5833, val_f1: 0.2532\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.9068, acc: 0.6250\n",
            "loss: 0.9378, acc: 0.5965\n",
            "loss: 0.9250, acc: 0.6082\n",
            "loss: 0.9242, acc: 0.6056\n",
            "loss: 0.9198, acc: 0.6044\n",
            "> val_acc: 0.5944, val_f1: 0.3376\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.8947, acc: 0.6068\n",
            "loss: 0.8721, acc: 0.6221\n",
            "loss: 0.8811, acc: 0.6196\n",
            "loss: 0.8712, acc: 0.6211\n",
            "loss: 0.8555, acc: 0.6267\n",
            "> val_acc: 0.6917, val_f1: 0.5431\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.6630, acc: 0.7094\n",
            "loss: 0.6956, acc: 0.7021\n",
            "loss: 0.6670, acc: 0.7175\n",
            "loss: 0.6749, acc: 0.7152\n",
            "loss: 0.6570, acc: 0.7243\n",
            "> val_acc: 0.7500, val_f1: 0.6425\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.6119, acc: 0.7578\n",
            "loss: 0.5683, acc: 0.7857\n",
            "loss: 0.5516, acc: 0.7917\n",
            "loss: 0.5657, acc: 0.7794\n",
            "loss: 0.5651, acc: 0.7781\n",
            "> val_acc: 0.7944, val_f1: 0.7119\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.5233, acc: 0.8073\n",
            "loss: 0.5260, acc: 0.7921\n",
            "loss: 0.4896, acc: 0.8071\n",
            "loss: 0.4832, acc: 0.8092\n",
            "loss: 0.4806, acc: 0.8085\n",
            "> val_acc: 0.7917, val_f1: 0.6976\n",
            "epoch: 8\n",
            "loss: 0.3962, acc: 0.8203\n",
            "loss: 0.3968, acc: 0.8385\n",
            "loss: 0.3984, acc: 0.8459\n",
            "loss: 0.4057, acc: 0.8403\n",
            "loss: 0.4015, acc: 0.8452\n",
            "> val_acc: 0.8194, val_f1: 0.7552\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.2857, acc: 0.8594\n",
            "loss: 0.3188, acc: 0.8849\n",
            "loss: 0.3334, acc: 0.8743\n",
            "loss: 0.3421, acc: 0.8690\n",
            "loss: 0.3451, acc: 0.8666\n",
            "loss: 0.3454, acc: 0.8685\n",
            "> val_acc: 0.8250, val_f1: 0.7569\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            ">> test_acc: 0.8286, test_f1: 0.7186\n",
            "fold : 4\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.2772, acc: 0.4781\n",
            "loss: 1.1173, acc: 0.5484\n",
            "loss: 1.0636, acc: 0.5719\n",
            "loss: 1.0386, acc: 0.5758\n",
            "loss: 1.0236, acc: 0.5781\n",
            "> val_acc: 0.5889, val_f1: 0.2471\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9494, acc: 0.6059\n",
            "loss: 0.9611, acc: 0.5880\n",
            "loss: 0.9449, acc: 0.5986\n",
            "loss: 0.9383, acc: 0.6010\n",
            "loss: 0.9348, acc: 0.6030\n",
            "> val_acc: 0.5861, val_f1: 0.2554\n",
            "epoch: 2\n",
            "loss: 0.8889, acc: 0.6074\n",
            "loss: 0.8951, acc: 0.5972\n",
            "loss: 0.8632, acc: 0.6161\n",
            "loss: 0.8471, acc: 0.6271\n",
            "loss: 0.8166, acc: 0.6406\n",
            "> val_acc: 0.7028, val_f1: 0.5734\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.6801, acc: 0.6897\n",
            "loss: 0.6570, acc: 0.7096\n",
            "loss: 0.6393, acc: 0.7251\n",
            "loss: 0.6324, acc: 0.7302\n",
            "loss: 0.6295, acc: 0.7347\n",
            "> val_acc: 0.7194, val_f1: 0.6082\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.5433, acc: 0.7786\n",
            "loss: 0.5497, acc: 0.7725\n",
            "loss: 0.5485, acc: 0.7716\n",
            "loss: 0.5464, acc: 0.7691\n",
            "loss: 0.5443, acc: 0.7745\n",
            "> val_acc: 0.7361, val_f1: 0.6596\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.4806, acc: 0.8344\n",
            "loss: 0.4988, acc: 0.8104\n",
            "loss: 0.4846, acc: 0.8075\n",
            "loss: 0.4740, acc: 0.8134\n",
            "loss: 0.4760, acc: 0.8104\n",
            "> val_acc: 0.7528, val_f1: 0.6779\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.3679, acc: 0.8555\n",
            "loss: 0.3981, acc: 0.8493\n",
            "loss: 0.3940, acc: 0.8477\n",
            "loss: 0.4093, acc: 0.8424\n",
            "loss: 0.4138, acc: 0.8384\n",
            "> val_acc: 0.7694, val_f1: 0.6971\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.3091, acc: 0.9062\n",
            "loss: 0.3552, acc: 0.8714\n",
            "loss: 0.3600, acc: 0.8689\n",
            "loss: 0.3780, acc: 0.8584\n",
            "loss: 0.3799, acc: 0.8525\n",
            "> val_acc: 0.7556, val_f1: 0.7033\n",
            "epoch: 8\n",
            "loss: 0.2580, acc: 0.8906\n",
            "loss: 0.3170, acc: 0.8698\n",
            "loss: 0.2982, acc: 0.8835\n",
            "loss: 0.2914, acc: 0.8872\n",
            "loss: 0.2914, acc: 0.8876\n",
            "> val_acc: 0.8000, val_f1: 0.7418\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.1682, acc: 0.9375\n",
            "loss: 0.2261, acc: 0.9134\n",
            "loss: 0.2353, acc: 0.9122\n",
            "loss: 0.2479, acc: 0.9042\n",
            "loss: 0.2461, acc: 0.9051\n",
            "loss: 0.2490, acc: 0.9024\n",
            "> val_acc: 0.7861, val_f1: 0.7149\n",
            ">> test_acc: 0.8277, test_f1: 0.7240\n",
            "fold : 5\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.0484, acc: 0.5734\n",
            "loss: 1.0023, acc: 0.5883\n",
            "loss: 0.9891, acc: 0.5818\n",
            "loss: 0.9724, acc: 0.5895\n",
            "loss: 0.9405, acc: 0.6038\n",
            "> val_acc: 0.6861, val_f1: 0.4655\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.7570, acc: 0.7066\n",
            "loss: 0.7686, acc: 0.6850\n",
            "loss: 0.7392, acc: 0.6972\n",
            "loss: 0.7187, acc: 0.7059\n",
            "loss: 0.7033, acc: 0.7130\n",
            "> val_acc: 0.7528, val_f1: 0.5806\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 2\n",
            "loss: 0.6181, acc: 0.7539\n",
            "loss: 0.6163, acc: 0.7526\n",
            "loss: 0.6131, acc: 0.7517\n",
            "loss: 0.5969, acc: 0.7607\n",
            "loss: 0.5939, acc: 0.7591\n",
            "> val_acc: 0.7667, val_f1: 0.6899\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.5564, acc: 0.8013\n",
            "loss: 0.5409, acc: 0.7923\n",
            "loss: 0.5116, acc: 0.8003\n",
            "loss: 0.5147, acc: 0.7965\n",
            "loss: 0.5127, acc: 0.7972\n",
            "> val_acc: 0.7528, val_f1: 0.6690\n",
            "epoch: 4\n",
            "loss: 0.4062, acc: 0.8203\n",
            "loss: 0.4168, acc: 0.8271\n",
            "loss: 0.4267, acc: 0.8329\n",
            "loss: 0.4490, acc: 0.8216\n",
            "loss: 0.4417, acc: 0.8227\n",
            "> val_acc: 0.7806, val_f1: 0.6909\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.3860, acc: 0.8344\n",
            "loss: 0.3465, acc: 0.8646\n",
            "loss: 0.3504, acc: 0.8700\n",
            "loss: 0.3524, acc: 0.8674\n",
            "loss: 0.3492, acc: 0.8681\n",
            "> val_acc: 0.7889, val_f1: 0.7247\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.2495, acc: 0.9102\n",
            "loss: 0.2592, acc: 0.9107\n",
            "loss: 0.2822, acc: 0.8991\n",
            "loss: 0.2872, acc: 0.8929\n",
            "loss: 0.2914, acc: 0.8896\n",
            "> val_acc: 0.7889, val_f1: 0.7151\n",
            "epoch: 7\n",
            "loss: 0.2152, acc: 0.9427\n",
            "loss: 0.2218, acc: 0.9315\n",
            "loss: 0.2232, acc: 0.9232\n",
            "loss: 0.2298, acc: 0.9176\n",
            "loss: 0.2374, acc: 0.9161\n",
            "> val_acc: 0.7917, val_f1: 0.7078\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 8\n",
            "loss: 0.1832, acc: 0.9375\n",
            "loss: 0.1978, acc: 0.9284\n",
            "loss: 0.2000, acc: 0.9247\n",
            "loss: 0.1975, acc: 0.9253\n",
            "loss: 0.1934, acc: 0.9278\n",
            "> val_acc: 0.8056, val_f1: 0.7441\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.1965, acc: 0.9531\n",
            "loss: 0.1422, acc: 0.9460\n",
            "loss: 0.1426, acc: 0.9479\n",
            "loss: 0.1394, acc: 0.9481\n",
            "loss: 0.1474, acc: 0.9470\n",
            "loss: 0.1395, acc: 0.9489\n",
            "> val_acc: 0.8139, val_f1: 0.7481\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            ">> test_acc: 0.8402, test_f1: 0.7496\n",
            "fold : 6\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.1048, acc: 0.4625\n",
            "loss: 1.0234, acc: 0.5383\n",
            "loss: 1.0003, acc: 0.5615\n",
            "loss: 0.9905, acc: 0.5617\n",
            "loss: 0.9695, acc: 0.5697\n",
            "> val_acc: 0.5944, val_f1: 0.2802\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.8417, acc: 0.6267\n",
            "loss: 0.8436, acc: 0.6308\n",
            "loss: 0.8057, acc: 0.6482\n",
            "loss: 0.7795, acc: 0.6591\n",
            "loss: 0.7624, acc: 0.6677\n",
            "> val_acc: 0.7389, val_f1: 0.5688\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 2\n",
            "loss: 0.6306, acc: 0.7461\n",
            "loss: 0.5927, acc: 0.7543\n",
            "loss: 0.5872, acc: 0.7584\n",
            "loss: 0.5931, acc: 0.7586\n",
            "loss: 0.6045, acc: 0.7533\n",
            "> val_acc: 0.7528, val_f1: 0.6490\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.5414, acc: 0.7679\n",
            "loss: 0.5238, acc: 0.7868\n",
            "loss: 0.5195, acc: 0.7882\n",
            "loss: 0.5143, acc: 0.7867\n",
            "loss: 0.5149, acc: 0.7892\n",
            "> val_acc: 0.7611, val_f1: 0.6571\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.4720, acc: 0.7943\n",
            "loss: 0.4596, acc: 0.8066\n",
            "loss: 0.4362, acc: 0.8233\n",
            "loss: 0.4352, acc: 0.8242\n",
            "loss: 0.4404, acc: 0.8210\n",
            "> val_acc: 0.7556, val_f1: 0.6239\n",
            "epoch: 5\n",
            "loss: 0.4113, acc: 0.8219\n",
            "loss: 0.3930, acc: 0.8385\n",
            "loss: 0.3715, acc: 0.8469\n",
            "loss: 0.3845, acc: 0.8424\n",
            "loss: 0.3767, acc: 0.8483\n",
            "> val_acc: 0.7611, val_f1: 0.6779\n",
            "epoch: 6\n",
            "loss: 0.3311, acc: 0.8750\n",
            "loss: 0.3161, acc: 0.8828\n",
            "loss: 0.2904, acc: 0.8978\n",
            "loss: 0.2837, acc: 0.8943\n",
            "loss: 0.2895, acc: 0.8913\n",
            "> val_acc: 0.7889, val_f1: 0.7120\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.2494, acc: 0.9323\n",
            "loss: 0.2335, acc: 0.9219\n",
            "loss: 0.2267, acc: 0.9212\n",
            "loss: 0.2302, acc: 0.9228\n",
            "loss: 0.2426, acc: 0.9179\n",
            "> val_acc: 0.7778, val_f1: 0.6997\n",
            "epoch: 8\n",
            "loss: 0.2065, acc: 0.9062\n",
            "loss: 0.2165, acc: 0.9180\n",
            "loss: 0.2168, acc: 0.9219\n",
            "loss: 0.2252, acc: 0.9189\n",
            "loss: 0.2264, acc: 0.9185\n",
            "> val_acc: 0.7694, val_f1: 0.6928\n",
            "epoch: 9\n",
            "loss: 0.1247, acc: 0.9375\n",
            "loss: 0.1311, acc: 0.9545\n",
            "loss: 0.1485, acc: 0.9472\n",
            "loss: 0.1520, acc: 0.9466\n",
            "loss: 0.1629, acc: 0.9428\n",
            "loss: 0.1797, acc: 0.9353\n",
            "> val_acc: 0.7639, val_f1: 0.6904\n",
            ">> test_acc: 0.8098, test_f1: 0.7091\n",
            "fold : 7\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.0770, acc: 0.5125\n",
            "loss: 1.0062, acc: 0.5703\n",
            "loss: 0.9862, acc: 0.5854\n",
            "loss: 0.9869, acc: 0.5840\n",
            "loss: 0.9911, acc: 0.5772\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9592, acc: 0.5851\n",
            "loss: 0.9413, acc: 0.5970\n",
            "loss: 0.9441, acc: 0.5905\n",
            "loss: 0.9370, acc: 0.5962\n",
            "loss: 0.9512, acc: 0.5944\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 2\n",
            "loss: 0.9918, acc: 0.5957\n",
            "loss: 0.9843, acc: 0.5911\n",
            "loss: 0.9834, acc: 0.5960\n",
            "loss: 0.9829, acc: 0.5921\n",
            "loss: 0.9846, acc: 0.5908\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 3\n",
            "loss: 0.9791, acc: 0.6004\n",
            "loss: 0.9488, acc: 0.6149\n",
            "loss: 0.9652, acc: 0.6036\n",
            "loss: 0.9672, acc: 0.6014\n",
            "loss: 0.9722, acc: 0.5964\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 4\n",
            "loss: 0.9896, acc: 0.5859\n",
            "loss: 0.9851, acc: 0.5889\n",
            "loss: 0.9636, acc: 0.6052\n",
            "loss: 0.9696, acc: 0.5998\n",
            "loss: 0.9673, acc: 0.5988\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 5\n",
            "loss: 0.9896, acc: 0.5656\n",
            "loss: 0.9556, acc: 0.6000\n",
            "loss: 0.9659, acc: 0.5931\n",
            "loss: 0.9668, acc: 0.5875\n",
            "loss: 0.9595, acc: 0.5951\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 6\n",
            "loss: 0.9840, acc: 0.5781\n",
            "loss: 0.9903, acc: 0.5725\n",
            "loss: 0.9733, acc: 0.5885\n",
            "loss: 0.9620, acc: 0.5956\n",
            "loss: 0.9566, acc: 0.6005\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 7\n",
            "loss: 0.9009, acc: 0.6667\n",
            "loss: 0.9373, acc: 0.6154\n",
            "loss: 0.9518, acc: 0.6033\n",
            "loss: 0.9590, acc: 0.6004\n",
            "loss: 0.9580, acc: 0.6003\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 8\n",
            "loss: 0.9646, acc: 0.5859\n",
            "loss: 0.9469, acc: 0.6016\n",
            "loss: 0.9454, acc: 0.6051\n",
            "loss: 0.9587, acc: 0.5977\n",
            "loss: 0.9590, acc: 0.5993\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            "epoch: 9\n",
            "loss: 0.9222, acc: 0.6094\n",
            "loss: 0.9360, acc: 0.6193\n",
            "loss: 0.9454, acc: 0.6042\n",
            "loss: 0.9361, acc: 0.6124\n",
            "loss: 0.9503, acc: 0.6002\n",
            "loss: 0.9522, acc: 0.5994\n",
            "> val_acc: 0.6083, val_f1: 0.2522\n",
            ">> test_acc: 0.6500, test_f1: 0.2626\n",
            "fold : 8\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.1356, acc: 0.5156\n",
            "loss: 1.0538, acc: 0.5555\n",
            "loss: 1.0317, acc: 0.5698\n",
            "loss: 1.0242, acc: 0.5766\n",
            "loss: 1.0161, acc: 0.5759\n",
            "> val_acc: 0.6056, val_f1: 0.2519\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9847, acc: 0.5729\n",
            "loss: 0.9446, acc: 0.6086\n",
            "loss: 0.9501, acc: 0.6034\n",
            "loss: 0.9562, acc: 0.5982\n",
            "loss: 0.9650, acc: 0.5925\n",
            "> val_acc: 0.6056, val_f1: 0.2519\n",
            "epoch: 2\n",
            "loss: 0.9508, acc: 0.5859\n",
            "loss: 0.9377, acc: 0.6016\n",
            "loss: 0.9231, acc: 0.6127\n",
            "loss: 0.9290, acc: 0.6020\n",
            "loss: 0.9306, acc: 0.6009\n",
            "> val_acc: 0.6028, val_f1: 0.2585\n",
            "epoch: 3\n",
            "loss: 0.8655, acc: 0.6228\n",
            "loss: 0.8704, acc: 0.6158\n",
            "loss: 0.8717, acc: 0.6186\n",
            "loss: 0.8449, acc: 0.6330\n",
            "loss: 0.8132, acc: 0.6449\n",
            "> val_acc: 0.7250, val_f1: 0.5426\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.6419, acc: 0.7318\n",
            "loss: 0.6322, acc: 0.7432\n",
            "loss: 0.6295, acc: 0.7410\n",
            "loss: 0.6300, acc: 0.7400\n",
            "loss: 0.6181, acc: 0.7415\n",
            "> val_acc: 0.7694, val_f1: 0.6525\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 5\n",
            "loss: 0.5174, acc: 0.7969\n",
            "loss: 0.5001, acc: 0.7906\n",
            "loss: 0.5133, acc: 0.7913\n",
            "loss: 0.5108, acc: 0.7920\n",
            "loss: 0.5105, acc: 0.7913\n",
            "> val_acc: 0.7639, val_f1: 0.6589\n",
            "epoch: 6\n",
            "loss: 0.4132, acc: 0.8242\n",
            "loss: 0.4339, acc: 0.8326\n",
            "loss: 0.4253, acc: 0.8294\n",
            "loss: 0.4350, acc: 0.8212\n",
            "loss: 0.4397, acc: 0.8210\n",
            "> val_acc: 0.7722, val_f1: 0.6902\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.3553, acc: 0.8906\n",
            "loss: 0.3622, acc: 0.8654\n",
            "loss: 0.3593, acc: 0.8628\n",
            "loss: 0.3564, acc: 0.8641\n",
            "loss: 0.3549, acc: 0.8637\n",
            "> val_acc: 0.7972, val_f1: 0.7288\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 8\n",
            "loss: 0.3062, acc: 0.8828\n",
            "loss: 0.3223, acc: 0.8672\n",
            "loss: 0.3169, acc: 0.8750\n",
            "loss: 0.3318, acc: 0.8696\n",
            "loss: 0.3248, acc: 0.8750\n",
            "> val_acc: 0.8167, val_f1: 0.7439\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.2238, acc: 0.8906\n",
            "loss: 0.2110, acc: 0.9148\n",
            "loss: 0.2098, acc: 0.9174\n",
            "loss: 0.2261, acc: 0.9133\n",
            "loss: 0.2300, acc: 0.9093\n",
            "loss: 0.2348, acc: 0.9086\n",
            "> val_acc: 0.7722, val_f1: 0.7092\n",
            ">> test_acc: 0.8402, test_f1: 0.7490\n",
            "fold : 9\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "epoch: 0\n",
            "loss: 1.0061, acc: 0.5656\n",
            "loss: 1.0058, acc: 0.5555\n",
            "loss: 0.9998, acc: 0.5599\n",
            "loss: 1.0038, acc: 0.5656\n",
            "loss: 0.9908, acc: 0.5706\n",
            "> val_acc: 0.6141, val_f1: 0.2536\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 1\n",
            "loss: 0.9420, acc: 0.6007\n",
            "loss: 0.9067, acc: 0.6217\n",
            "loss: 0.9329, acc: 0.5970\n",
            "loss: 0.9185, acc: 0.5946\n",
            "loss: 0.9020, acc: 0.5992\n",
            "> val_acc: 0.6685, val_f1: 0.5387\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 2\n",
            "loss: 0.7403, acc: 0.6855\n",
            "loss: 0.7301, acc: 0.6719\n",
            "loss: 0.7143, acc: 0.6864\n",
            "loss: 0.6913, acc: 0.6986\n",
            "loss: 0.6970, acc: 0.6940\n",
            "> val_acc: 0.7935, val_f1: 0.6917\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 3\n",
            "loss: 0.5914, acc: 0.7634\n",
            "loss: 0.5922, acc: 0.7518\n",
            "loss: 0.5770, acc: 0.7517\n",
            "loss: 0.5794, acc: 0.7538\n",
            "loss: 0.5733, acc: 0.7563\n",
            "> val_acc: 0.8071, val_f1: 0.7307\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 4\n",
            "loss: 0.5483, acc: 0.7630\n",
            "loss: 0.4889, acc: 0.8027\n",
            "loss: 0.4727, acc: 0.8053\n",
            "loss: 0.4770, acc: 0.8051\n",
            "loss: 0.4910, acc: 0.7986\n",
            "> val_acc: 0.7989, val_f1: 0.7243\n",
            "epoch: 5\n",
            "loss: 0.3867, acc: 0.8625\n",
            "loss: 0.4158, acc: 0.8313\n",
            "loss: 0.4196, acc: 0.8313\n",
            "loss: 0.4258, acc: 0.8290\n",
            "loss: 0.4144, acc: 0.8358\n",
            "> val_acc: 0.8207, val_f1: 0.7601\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 6\n",
            "loss: 0.2913, acc: 0.8906\n",
            "loss: 0.3049, acc: 0.8828\n",
            "loss: 0.3023, acc: 0.8861\n",
            "loss: 0.3207, acc: 0.8819\n",
            "loss: 0.3276, acc: 0.8757\n",
            "> val_acc: 0.8234, val_f1: 0.7587\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 7\n",
            "loss: 0.2036, acc: 0.9375\n",
            "loss: 0.2665, acc: 0.9075\n",
            "loss: 0.2682, acc: 0.9015\n",
            "loss: 0.2703, acc: 0.8991\n",
            "loss: 0.2694, acc: 0.9008\n",
            "> val_acc: 0.8234, val_f1: 0.7384\n",
            "epoch: 8\n",
            "loss: 0.3421, acc: 0.8594\n",
            "loss: 0.2416, acc: 0.9049\n",
            "loss: 0.2294, acc: 0.9098\n",
            "loss: 0.2132, acc: 0.9160\n",
            "loss: 0.2061, acc: 0.9196\n",
            "> val_acc: 0.8288, val_f1: 0.7652\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            "epoch: 9\n",
            "loss: 0.0920, acc: 0.9688\n",
            "loss: 0.1537, acc: 0.9403\n",
            "loss: 0.1583, acc: 0.9390\n",
            "loss: 0.1605, acc: 0.9385\n",
            "loss: 0.1698, acc: 0.9360\n",
            "loss: 0.1745, acc: 0.9343\n",
            "> val_acc: 0.8342, val_f1: 0.7739\n",
            ">> saved: state_dict/bert_spc_restaurant_val_temp\n",
            ">> test_acc: 0.8375, test_f1: 0.7614\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            ">>> mean_test_acc: 0.8088, mean_test_f1: 0.6809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwQBZ-Ae27-j",
        "colab_type": "code",
        "outputId": "d1b1affd-8ba0-42f2-838a-a9498d634a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "!python infer_example.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading tokenizer: restaurant_tokenizer.dat\n",
            "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n",
            "loading model memnet ...\n",
            "/content/ABSA-PyTorch/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "tensor([[-0.6929,  0.0209,  1.1477],\n",
            "        [ 0.6735, -0.0847, -0.2983],\n",
            "        [ 0.2194, -0.2016,  0.2813]], device='cuda:0')\n",
            "[ 1 -1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}